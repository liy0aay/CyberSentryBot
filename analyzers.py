import re
import base64
import requests
from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification


class VirusTotalClient:
    def __init__(self, api_key: str):
        self.api_key = api_key
        self.headers = {'x-apikey': self.api_key}

    def _handle_api_error(self, response, url: str) -> dict:
        if response.status_code == 404:
            scan_url = 'https://www.virustotal.com/api/v3/urls'
            resp = requests.post(scan_url, headers=self.headers, data={'url': url})
            if resp.status_code == 200:
                return {
                    'status': 'queued',
                    'message': 'URL –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω –Ω–∞ –∞–Ω–∞–ª–∏–∑. –ü–æ–≤—Ç–æ—Ä–∏—Ç–µ –ø–æ–∑–∂–µ.'
                }
            return {'error': f"–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏: {resp.status_code}"}
        if response.status_code == 429:
            return {'error': '–ü—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç –∑–∞–ø—Ä–æ—Å–æ–≤'}
        return {'error': f'–û—à–∏–±–∫–∞ API: {response.status_code}'}

    def check_url(self, url: str) -> dict:
        try:
            encoded = base64.urlsafe_b64encode(url.encode()).decode().rstrip("=")
            api_url = f'https://www.virustotal.com/api/v3/urls/{encoded}'
            resp = requests.get(api_url, headers=self.headers, timeout=10)

            if resp.status_code == 200:
                stats = (
                    resp.json()
                    .get('data', {})
                    .get('attributes', {})
                    .get('last_analysis_stats', {})
                )
                return {
                    'malicious': stats.get('malicious', 0),
                    'suspicious': stats.get('suspicious', 0),
                    'harmless': stats.get('harmless', 0),
                }

            return self._handle_api_error(resp, url)

        except requests.exceptions.RequestException as e:
            return {'error': f"–û—à–∏–±–∫–∞ —Å–µ—Ç–∏: {e}"}
        except Exception as e:
            return {'error': f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞: {e}"}


class BaseAnalyzer:
    def analyze_message(self, text: str) -> list:
        raise NotImplementedError(
            "–ú–µ—Ç–æ–¥ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω –≤ –ø–æ–¥–∫–ª–∞—Å—Å–µ"
        )


class PhishingAnalyzer(BaseAnalyzer):
    def __init__(self, vt_client: VirusTotalClient, nlp_pipeline=None, tokenizer=None):
        self.vt_client = vt_client
        self.nlp = nlp_pipeline
        self.tokenizer = tokenizer

    def analyze_text(self, text: str) -> dict:
        if not self.nlp or not self.tokenizer:
            return {'error': '–ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞'}

        try:
            inputs = self.tokenizer(
                text, return_tensors="pt", truncation=True, max_length=512
            )
            truncated = self.tokenizer.decode(
                inputs["input_ids"][0], skip_special_tokens=True
            )
            result = self.nlp(truncated)[0]
            return {
                'label': 'phishing' if result['label'] == 'LABEL_1' else 'safe',
                'score': result['score'],
            }
        except Exception as e:
            return {'error': str(e)}

    def extract_urls(self, text: str) -> list:
        return re.findall(
            r'(?:(?:https?|ftp):\/\/)?'
            r'(?:www\.)?'
            r'(?:[a-zA-Z0-9-]+\.)+[a-zA-Z]{2,}'
            r'(?:\/[^\s]*)?',
            text
        )

    def _check_url_risk(self, url: str) -> str: # –º–µ—Ç–æ–¥ —Å—Ç—Ä–æ–≥–æ –≤–Ω—É—Ç—Ä–∏ –∫–ª–∞—Å—Å–∞
        full_url = url if url.startswith(('http://', 'https://', 'ftp://')) \
            else f'http://{url}'
        try:
            response = requests.get(
                full_url, allow_redirects=True, timeout=7,
                headers={'User-Agent': 'Mozilla/5.0'}
            )
            expanded = response.url
            result = self.vt_client.check_url(expanded)

            if result.get('error'):
                return f"    - `{url}`: ‚ö†Ô∏è {result['error']}"
            if result.get('status') == 'queued':
                return f"    - `{url}`: ‚è≥ –û—Ç–ø—Ä–∞–≤–ª–µ–Ω –Ω–∞ –∞–Ω–∞–ª–∏–∑"
            if result.get('malicious', 0) > 1 or result.get('suspicious', 0) > 1:
                return f"    - `{url}`: üî¥ –û–ø–∞—Å–Ω–æ"
            if result.get('malicious', 0) > 0 or result.get('suspicious', 0) > 0:
                return f"    - `{url}`: üü° –ü–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–æ"
            return f"    - `{url}`: ‚úÖ –ë–µ–∑–æ–ø–∞—Å–Ω–æ"
        except Exception as e:
            return f"    - `{url}`: ‚ö†Ô∏è –û—à–∏–±–∫–∞ ({type(e).__name__})"

    def analyze_message(self, text: str) -> list:
        report = []

        urls = self.extract_urls(text)
        if urls:
            report.append("üîé –ê–Ω–∞–ª–∏–∑ —Å—Å—ã–ª–æ–∫:")
            for url in urls:
                report.append(self._check_url_risk(url))
        else:
            report.append("‚ÑπÔ∏è –°—Å—ã–ª–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã.")

        report.append("\nüìù –ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞:")
        result = self.analyze_text(text)

        if result.get('error'):
            report.append(f"    - –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ–∫—Å—Ç–∞: {result['error']}")
        elif result['label'] == 'phishing' and result['score'] > 0.5:
            confidence = f"{result['score']:.0%}"
            report.append(f"    - üü° –ü–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence})")
        else:
            report.append("    - ‚úÖ –¢–µ–∫—Å—Ç –Ω–µ –≤—ã–≥–ª—è–¥–∏—Ç –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã–º.")

        return report